{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lc-QuAD 2.0 Cluster Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>new_LabelsEnt</th>\n",
       "      <th>new_LabelsRel</th>\n",
       "      <th>sparql_wikidata</th>\n",
       "      <th>template_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>['Delta Air Lines: wd:Q188920', 'periodical: w...</td>\n",
       "      <td>['house publication: wdt:P2813', 'instance of:...</td>\n",
       "      <td>select distinct ?obj where { wd:Q188920 wdt:P2...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the child of Ranavalona I's husband?</td>\n",
       "      <td>['Ranavalona I of Madagascar: wd:Q169794']</td>\n",
       "      <td>['spouse: wdt:P26', 'father: wdt:P22']</td>\n",
       "      <td>SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X ....</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the pre-requisite of phase matter of G...</td>\n",
       "      <td>['Galinstan: wd:Q675176']</td>\n",
       "      <td>['phase of matter: wdt:P515', 'followed by: wd...</td>\n",
       "      <td>SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What periodical literature does Delta Air Line...   \n",
       "1        Who is the child of Ranavalona I's husband?   \n",
       "2  What is the pre-requisite of phase matter of G...   \n",
       "\n",
       "                                       new_LabelsEnt  \\\n",
       "0  ['Delta Air Lines: wd:Q188920', 'periodical: w...   \n",
       "1         ['Ranavalona I of Madagascar: wd:Q169794']   \n",
       "2                          ['Galinstan: wd:Q675176']   \n",
       "\n",
       "                                       new_LabelsRel  \\\n",
       "0  ['house publication: wdt:P2813', 'instance of:...   \n",
       "1             ['spouse: wdt:P26', 'father: wdt:P22']   \n",
       "2  ['phase of matter: wdt:P515', 'followed by: wd...   \n",
       "\n",
       "                                     sparql_wikidata template_id  label  \n",
       "0  select distinct ?obj where { wd:Q188920 wdt:P2...           1      4  \n",
       "1  SELECT ?answer WHERE { wd:Q169794 wdt:P26 ?X ....           5      1  \n",
       "2  SELECT ?answer WHERE { wd:Q675176 wdt:P515 ?X ...           2      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('../data/LC-QuAD2.0/final_train_lcquad2_cluster.csv')\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1,  3,  5,  6,  2,  0,  8,  7,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 5628.18it/s]\n",
      "100%|██████████| 24180/24180 [05:43<00:00, 70.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "# Load model\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "# Initialize an empty dictionary to store embeddings\n",
    "embedding_space = {}\n",
    "\n",
    "# Iterate over the dataset\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    q = str(train_data.iloc[i]['question'])  # Question\n",
    "    e = str(train_data.iloc[i]['new_LabelsEnt'])  # Entity label\n",
    "    r = str(train_data.iloc[i]['new_LabelsRel'])  # Relation label\n",
    "    s = str(train_data.iloc[i]['sparql_wikidata'])  # SPARQL query\n",
    "    \n",
    "    # Create a unique key by concatenating the fields with tab delimiters\n",
    "    key = q + '\\t' + e + '\\t' + r + '\\t' + s\n",
    "    \n",
    "    # Compute the embedding for the question and store it in the dictionary\n",
    "    embedding_space[key] = model.encode(q)['dense_vecs']\n",
    "\n",
    "# Save the embedding space dictionary as a pickle file\n",
    "with open('../data/embedding/base/train_question_embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space, f)\n",
    "\n",
    "print(\"Embeddings saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24180/24180 [05:44<00:00, 70.12it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_space_0 = {}\n",
    "embedding_space_1 = {}\n",
    "embedding_space_2 = {}\n",
    "embedding_space_3 = {}\n",
    "embedding_space_4 = {}\n",
    "embedding_space_5 = {}\n",
    "embedding_space_6 = {}\n",
    "embedding_space_7 = {}\n",
    "embedding_space_8 = {}\n",
    "embedding_space_9 = {}\n",
    "embedding_space_10 = {}\n",
    "embedding_space_11 = {}\n",
    "embedding_space_12 = {}\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    q = str(train_data.iloc[i]['question'])\n",
    "    e = str(train_data.iloc[i]['new_LabelsEnt'])\n",
    "    r = str(train_data.iloc[i]['new_LabelsRel'])\n",
    "    s = str(train_data.iloc[i]['sparql_wikidata'])\n",
    "    key = q + '\\t' + e + '\\t' + r + '\\t' + s\n",
    "    if train_data.iloc[i]['label'] == 0:\n",
    "        embedding_space_0[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 1:\n",
    "        embedding_space_1[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 2:\n",
    "        embedding_space_2[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 3:\n",
    "        embedding_space_3[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 4:\n",
    "        embedding_space_4[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 5:\n",
    "        embedding_space_5[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 6:\n",
    "        embedding_space_6[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 7:\n",
    "        embedding_space_7[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 8:\n",
    "        embedding_space_8[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 9:\n",
    "        embedding_space_9[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 10:\n",
    "        embedding_space_10[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 11:\n",
    "        embedding_space_11[key] = model.encode(q)['dense_vecs']\n",
    "    elif train_data.iloc[i]['label'] == 12:\n",
    "        embedding_space_12[key] = model.encode(q)['dense_vecs']\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_0.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_0, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_1.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_1, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_2.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_2, f)\n",
    "\n",
    "with open('../data/embedding/cluster/embedding_space_3.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_3, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_4.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_4, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_5.pkl', 'wb') as f:    \n",
    "    pickle.dump(embedding_space_5, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_6.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_6, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_7.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_7, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_8.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_8, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_9.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_9, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_10.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_10, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_11.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_11, f)\n",
    "    \n",
    "with open('../data/embedding/cluster/embedding_space_12.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_space_12, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster & Embedding Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query, model, es_num, top_k=3):\n",
    "    # 저장된 embedding space를 불러옴\n",
    "    with open(f'../paper/data/embedding/cluster/embedding_space_{es_num}.pkl', 'rb') as f:\n",
    "        embedding_space = pickle.load(f)\n",
    "    \n",
    "    # query를 임베딩\n",
    "    query_embedding = model.encode(query)['dense_vecs']\n",
    "    \n",
    "    # 유사도를 저장할 리스트\n",
    "    similarities = []\n",
    "\n",
    "    # 각 embedding space에서 query와의 유사도 계산\n",
    "    for key, embedding in embedding_space.items():\n",
    "        # 코사인 유사도를 계산\n",
    "        sim = cosine_similarity(query_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
    "        similarities.append((key, sim))\n",
    "    \n",
    "    # 유사도 기준으로 상위 top_k개의 결과 정렬\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 7141,\n",
       " 'question': 'What was the population of Somalia in 2009-0-0?',\n",
       " 'sparql_wikidata': \"SELECT ?obj WHERE { wd:Q1045 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),'2009')) }\",\n",
       " 'template_id': 'statement_property_2',\n",
       " 'token_id_list': ['wd:Q1045', 'p:P1082', 'ps:P1082', 'pq:P585'],\n",
       " 'entities': ['Somalia'],\n",
       " 'relations': ['population', 'population', 'point in time'],\n",
       " 'new_LabelsEnt': ['Somalia: wd:Q1045'],\n",
       " 'new_LabelsRel': ['population: p:P1082',\n",
       "  'population: ps:P1082',\n",
       "  'point in time: pq:P585'],\n",
       " 'answer': ['9380854']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/LC-QuAD2.0/final_test_lcquad2.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql_wikidata</th>\n",
       "      <th>template_id</th>\n",
       "      <th>token_id_list</th>\n",
       "      <th>entities</th>\n",
       "      <th>relations</th>\n",
       "      <th>new_LabelsEnt</th>\n",
       "      <th>new_LabelsRel</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20258</td>\n",
       "      <td>Who is the  {country} for {head of state} of {...</td>\n",
       "      <td>select distinct ?sbj where { ?sbj wdt:P35 wd:Q...</td>\n",
       "      <td>2</td>\n",
       "      <td>[wdt:P35, wd:Q127998, wdt:P31, wd:Q6256]</td>\n",
       "      <td>[Mahmoud Abbas, country]</td>\n",
       "      <td>[head of state, instance of]</td>\n",
       "      <td>[Mahmoud Abbas: wd:Q127998, country: wd:Q6256]</td>\n",
       "      <td>[head of state: wdt:P35, instance of: wdt:P31]</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q219060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7141</td>\n",
       "      <td>What was the population of Somalia in 2009-0-0?</td>\n",
       "      <td>SELECT ?obj WHERE { wd:Q1045 p:P1082 ?s . ?s p...</td>\n",
       "      <td>statement_property_2</td>\n",
       "      <td>[wd:Q1045, p:P1082, ps:P1082, pq:P585]</td>\n",
       "      <td>[Somalia]</td>\n",
       "      <td>[population, population, point in time]</td>\n",
       "      <td>[Somalia: wd:Q1045]</td>\n",
       "      <td>[population: p:P1082, population: ps:P1082, po...</td>\n",
       "      <td>[9380854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12761</td>\n",
       "      <td>Which female actress is the voice over on Sout...</td>\n",
       "      <td>SELECT ?answer WHERE { wd:Q16538 wdt:P725 ?ans...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wd:Q16538, wdt:P725, wdt:P106, wd:Q177220]</td>\n",
       "      <td>[South Park, singer]</td>\n",
       "      <td>[voice actor, occupation]</td>\n",
       "      <td>[South Park: wd:Q16538, singer: wd:Q177220]</td>\n",
       "      <td>[voice actor: wdt:P725, occupation: wdt:P106]</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q44414, http:/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid                                           question  \\\n",
       "0  20258  Who is the  {country} for {head of state} of {...   \n",
       "1   7141    What was the population of Somalia in 2009-0-0?   \n",
       "2  12761  Which female actress is the voice over on Sout...   \n",
       "\n",
       "                                     sparql_wikidata           template_id  \\\n",
       "0  select distinct ?sbj where { ?sbj wdt:P35 wd:Q...                     2   \n",
       "1  SELECT ?obj WHERE { wd:Q1045 p:P1082 ?s . ?s p...  statement_property_2   \n",
       "2  SELECT ?answer WHERE { wd:Q16538 wdt:P725 ?ans...                     1   \n",
       "\n",
       "                                 token_id_list                  entities  \\\n",
       "0     [wdt:P35, wd:Q127998, wdt:P31, wd:Q6256]  [Mahmoud Abbas, country]   \n",
       "1       [wd:Q1045, p:P1082, ps:P1082, pq:P585]                 [Somalia]   \n",
       "2  [wd:Q16538, wdt:P725, wdt:P106, wd:Q177220]      [South Park, singer]   \n",
       "\n",
       "                                 relations  \\\n",
       "0             [head of state, instance of]   \n",
       "1  [population, population, point in time]   \n",
       "2                [voice actor, occupation]   \n",
       "\n",
       "                                    new_LabelsEnt  \\\n",
       "0  [Mahmoud Abbas: wd:Q127998, country: wd:Q6256]   \n",
       "1                             [Somalia: wd:Q1045]   \n",
       "2     [South Park: wd:Q16538, singer: wd:Q177220]   \n",
       "\n",
       "                                       new_LabelsRel  \\\n",
       "0     [head of state: wdt:P35, instance of: wdt:P31]   \n",
       "1  [population: p:P1082, population: ps:P1082, po...   \n",
       "2      [voice actor: wdt:P725, occupation: wdt:P106]   \n",
       "\n",
       "                                              answer  \n",
       "0           [http://www.wikidata.org/entity/Q219060]  \n",
       "1                                          [9380854]  \n",
       "2  [http://www.wikidata.org/entity/Q44414, http:/...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/LC-QUAD2.0/final_test_lcquad2.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = '../bert_finetuning/best_model'\n",
    "tokenizer = AutoTokenizer.from_pretrained('../bert_finetuning/best_model')\n",
    "clf_model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "clf_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.eval()\n",
    "\n",
    "def get_prediction(model, query):\n",
    "    inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax().item()\n",
    "    return predicted_class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What was the population of Somalia in 2009-0-0?\n",
      "sparql: SELECT ?obj WHERE { wd:Q1045 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),'2009')) }\n",
      "es_num: 6\n",
      "\n",
      "Score: 0.7312590031988175\n",
      "Question: What was the population of Gambia in the year 2009?\n",
      "Entities: ['The Gambia: wd:Q1005']\n",
      "Relations: ['population: p:P1082', 'population: ps:P1082', 'point in time: pq:P585']\n",
      "Sparql: SELECT ?obj WHERE { wd:Q1005 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),'2009')) }\n",
      "\n",
      "Score: 0.6179013580529926\n",
      "Question: In 2004, what was the population of Kenya?\n",
      "Entities: ['Kenya: wd:Q114']\n",
      "Relations: ['population: p:P1082', 'population: ps:P1082', 'point in time: pq:P585']\n",
      "Sparql: SELECT ?obj WHERE { wd:Q114 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),'2004')) }\n",
      "\n",
      "Score: 0.6093771957814875\n",
      "Question: What is the population of Yemen in the year 1994?\n",
      "Entities: ['Yemen: wd:Q805']\n",
      "Relations: ['population: p:P1082', 'population: ps:P1082', 'point in time: pq:P585']\n",
      "Sparql: SELECT ?obj WHERE { wd:Q805 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),'1994')) }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "\n",
    "query = test_data.iloc[idx]['question']\n",
    "sparql = test_data.iloc[idx]['sparql_wikidata']\n",
    "es_num = get_prediction(clf_model, query)\n",
    "\n",
    "print(\"query:\", query)\n",
    "print(\"sparql:\", sparql)\n",
    "print(\"es_num:\", es_num)\n",
    "print()\n",
    "\n",
    "sim_query = search(query, model, es_num)\n",
    "\n",
    "for i, (k, score) in enumerate(sim_query):\n",
    "    k = k.split('\\t')\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Question: {k[0]}\")\n",
    "    print(f\"Entities: {k[1]}\")\n",
    "    print(f\"Relations: {k[2]}\")\n",
    "    print(f\"Sparql: {k[3]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
